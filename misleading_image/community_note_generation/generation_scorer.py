"""
Scores a community note generation by comparing the generated note to the ground truth note, using an LLM.
"""

from misleading_image.gemini import Gemini
import json 
import pandas as pd 
import itertools
import re 

def get_scores(df: pd.DataFrame):
    """
    The dataframe should have columns 'generated_cn' and 'original_cn'.
    A new column 'score' will be added to the dataframe.
    """

    scores = []
    for index, row in df.iterrows():
        generated_cn = row['generated_cn']
        original_cn = row['original_cn']
        score_dict = score(generated_cn, original_cn)
        scores.append(score_dict['score'])

    df['score'] = scores
    return df


def score(generated_cn: str, original_cn : str):
    """
    Scores a community note generation by comparing the generated note to the ground truth note, using an LLM.
    """

    gemini = Gemini("misleading_image/google.key")
    prompt = ["Below are two community notes, one is the original from Twitter, another is generated by an LLM.",
              "Assume the original community note is entirely true and correct.",
              "Please score the generated community note based on how many factual differences it has compared to the original community note.",
              "Score from 0 to 1, where 0 is completely different and 1 is exactly the same. e.g. 0.3 for a pretty bad community note",
              "Give the score in following JSON format {'score': 0.3, 'reason': 'The generated note is missing some key details'}",
              "Original Community Note:",
              original_cn,
              "Generated Community Note:",
              generated_cn,
              "Score JSON:"]
    

    # no grounding
    # google grounding
    # just reverse image search
    # google grounding + reverse image search

    
    response_text = gemini.generate(prompt).text
    start = response_text.find("{")
    end = response_text.rfind("}")
    response_text = response_text[start:end+1]
    response_json = json.loads(response_text)

    # Return as a dict
    return response_json


def compare(original_cn: str, generated_cn_a: str, generated_cn_b: str) -> tuple[str, str]:
    """
    Compares a against b, and chooses the best one with a reason why.
    """
    prompt = [
        "Below are three community notes: one is the original from Twitter, and two are generated by an LLM.",
        "Assume the original community note is entirely true and correct.",
        "Between generated A and B, choose the one that best explains the original context of the tweet and uses the facts from the original community note.",
        "A good generated community note must:",
        "1. Include all the relevant facts and sources used in the original community note.",
        "2. Provide additional relevant context if possible.",
        "3. Not contradict the original community note.",
        "4. Be clear and factually accurate.",
        "You must choose either A or B and provide a reason why with a summary for each community note.",
        "------\n # Original Community Note:",
        original_cn,
        "------\n # Generated Community Note A:",
        generated_cn_a,
        "------\n # Generated Community Note B:",
        generated_cn_b,
        "Respond in the following JSON format with double quotes: e.g. {'choice': 'A', 'reason': 'Generated A has more relevant sources and provides additional context'}"
    ]

    # print("prompt:", prompt)

    gemini = Gemini("misleading_image/google.key")
    response = gemini.generate(prompt)
    response_text = response.text
    # print("response_text:", response_text)
    start = response_text.find("{")
    end = response_text.rfind("}")

    response_text = response_text[start:end+1]
    # Remove newlines
    response_text = response_text.replace("\n", "")
    response_text = response_text.replace("\t", "")
    response_text = response_text.replace("\r", "")

    no_space_response = re.sub(r"\s+", "", response_text)

    choice = no_space_response[no_space_response.find("choice") + 9: no_space_response.find("reason") - 3]
    reason = response_text[response_text.find("reason") + 10: -1]

    assert(choice.lower() in ['a', 'b']), f"{choice}"

    return {"choice": choice, "reason": reason}


def initialize_elo(df: pd.DataFrame, generated_columns: list[str], initial_rating: int = 1500):
    """
    Initializes ELO ratings for each generated column.
    """
    elo_scores = {col: initial_rating for col in generated_columns}
    return elo_scores

def update_elo(elo_scores, winner, loser, k=32):
    """
    Updates ELO scores using the standard ELO formula.
    """
    R_winner = elo_scores[winner]
    R_loser = elo_scores[loser]

    # Compute expected win probabilities
    E_winner = 1 / (1 + 10 ** ((R_loser - R_winner) / 400))
    E_loser = 1 - E_winner

    # Adjust scores
    elo_scores[winner] += k * (1 - E_winner)
    elo_scores[loser] += k * (0 - E_loser)

def rank(df: pd.DataFrame, original_column: str, generated_columns: list[str]):
    """
    Performs an ELO ranking system to rank the best generated community note.

    Returns a DataFrame showing:
    - Matchup (which notes were compared)
    - Winner (which note was chosen)
    - Reason (why it was chosen)
    - Updated ELO Scores
    """
    elo_scores = initialize_elo(df, generated_columns)
    results = []

    print("Rank start")

    for _, row in df.iterrows():
        original_cn = row[original_column]

        # Compare all pairs of generated notes
        for a, b in itertools.combinations(generated_columns, 2):
            generated_cn_a = row[a]
            generated_cn_b = row[b]

            # Compare the two generated notes
            result = compare(original_cn, generated_cn_a, generated_cn_b)
            winner_col = a if result['choice'].lower() == 'a' else b
            loser_col = b if result['choice'].lower() == 'a' else a

            print(f"{a} vs {b}, Winner: {winner_col}")

            # Update ELO scores
            update_elo(elo_scores, winner_col, loser_col)

            # Store results
            results.append({
                "Matchup": f"A: {a} vs B: {b}",
                "Winner": winner_col,
                "Reason": result['reason'],
                "ELO_After_Winner": elo_scores[winner_col],
                "ELO_After_Loser": elo_scores[loser_col],
                "Original_CN": original_cn,
                "A's CN": generated_cn_a,
                "B's CN": generated_cn_b
            })

    # Convert to DataFrame
    results_df = pd.DataFrame(results)
    
    # Display rankings
    ranking_df = pd.DataFrame(elo_scores.items(), columns=["Generated_Note", "ELO"]).sort_values(by="ELO", ascending=False)

    return results_df, ranking_df

    


if __name__ == "__main__":
    # Quick test
    original_cn = "The photo of Mark Zuckerberg was taken in 2012 during a trip to Maui, Hawaii with his wife:  https://www.dailymail.co.uk/news/article-2254889/Mark-Zuckerberg-Priscilla-Chan-surfing-Christmas-Hawaii.html"
    generated_cn = "This image is a fabricated Facebook post attributed to Mark Zuckerberg, making false claims about 'adrenochrome' and Little St. James Island. The real photo of Zuckerberg was taken in Hawaii in 2012. The adrenochrome conspiracy theory is linked to antisemitism and QAnon. [https://www.logicallyfacts.com/fact-checks/no-mark-zuckerberg-did-not-admit-to-ingesting-adrenochrome]"
    print(score(generated_cn, original_cn))

