"""
Scores a community note generation by comparing the generated note to the ground truth note, using an LLM.
"""

from misleading_image.gemini import Gemini
import json 
import pandas as pd 
import itertools
import re 
import random 

def get_scores(df: pd.DataFrame):
    """
    The dataframe should have columns 'generated_cn' and 'original_cn'.
    A new column 'score' will be added to the dataframe.
    """

    scores = []
    for index, row in df.iterrows():
        generated_cn = row['generated_cn']
        original_cn = row['original_cn']
        score_dict = score(generated_cn, original_cn)
        scores.append(score_dict['score'])

    df['score'] = scores
    return df


def score(generated_cn: str, original_cn : str):
    """
    Scores a community note generation by comparing the generated note to the ground truth note, using an LLM.
    """

    gemini = Gemini("misleading_image/google.key")
    prompt = ["Below are two community notes, one is the original from Twitter, another is generated by an LLM.",
              "Assume the original community note is entirely true and correct.",
              "Please score the generated community note based on how many factual differences it has compared to the original community note.",
              "Score from 0 to 1, where 0 is completely different and 1 is exactly the same. e.g. 0.3 for a pretty bad community note",
              "Give the score in following JSON format {'score': 0.3, 'reason': 'The generated note is missing some key details'}",
              "Original Community Note:",
              original_cn,
              "Generated Community Note:",
              generated_cn,
              "Score JSON:"]
    

    # no grounding
    # google grounding
    # just reverse image search
    # google grounding + reverse image search

    
    response_text = gemini.generate(prompt).text
    start = response_text.find("{")
    end = response_text.rfind("}")
    response_text = response_text[start:end+1]
    response_json = json.loads(response_text)

    # Return as a dict
    return response_json


def compare(original_cn: str, generated_cn_a: str, generated_cn_b: str) -> tuple[str, str]:
    """
    Compares a against b, and chooses the best one with a reason why.
    """
    prompt = [
        "Below are three community notes: one is the original from Twitter, and two are generated by an LLM.",
        "We assume the original community note is entirely true and correct.",
        "",
        "You will decide which of the two generated notes (A or B) is better, or if they are effectively the same, choose 'D' for a draw/tie. Specifically:",
        "1. A good generated note must include all of the key facts from the original note.",
        "2. It may include additional relevant sources or context, provided they do not contradict the original note.",
        "3. It must be factually accurate and clearly written.",
        "4. Only choose 'D' (draw) if both generated notes are essentially the same in how well they match (or fail to match) the original note.",
        "   - This includes cases where they are both nearly identical and convey essentially the same content.",
        "   - Do not choose 'D' just because both have some flaws or both differ from the original in different ways. In that scenario, you must pick whichever one is closer to the original's facts and clarity.",
        "------",
        "# Original Community Note:",
        original_cn,
        "------",
        "# Generated Community Note A:",
        generated_cn_a,
        "------",
        "# Generated Community Note B:",
        generated_cn_b,
        "",
        "Please respond with valid JSON in this format (with double quotes):",
        "{'choice': 'A', 'reason': 'Explain why A is better (or why it's a tie)'}",
        "Possible choices for 'choice' are only 'A', 'B', or 'D'."
    ]

    # print("prompt:", prompt)

    prompt = "\n".join(prompt)

    gemini = Gemini("misleading_image/google.key")
    response = gemini.generate(prompt)
    response_text = response.text
    # print("response_text:", response_text)
    start = response_text.find("{")
    end = response_text.rfind("}")

    response_text = response_text[start:end+1]
    # Remove newlines
    response_text = response_text.replace("\n", "")
    response_text = response_text.replace("\t", "")
    response_text = response_text.replace("\r", "")

    no_space_response = re.sub(r"\s+", "", response_text)

    choice = no_space_response[no_space_response.find("choice") + 9: no_space_response.find("reason") - 3]
    reason = response_text[response_text.find("reason") + 10: -1]

    if (choice.lower() not in ['a', 'b', 'd']):
        raise ValueError("Invalid choice of " + choice)

    return {"choice": choice, "reason": reason}


def initialize_elo(df: pd.DataFrame, generated_columns: list[str], initial_rating: int = 1500):
    """
    Initializes ELO ratings for each generated column.
    """
    elo_scores = {col: initial_rating for col in generated_columns}
    return elo_scores

def update_elo(elo_scores, winner, loser, draw=False, k=32):
    """
    Updates ELO scores using the standard ELO formula, now supporting draws.
    
    Parameters:
        elo_scores (dict): Dictionary mapping player names to ELO scores.
        winner (str): Name of the winning player.
        loser (str): Name of the losing player.
        draw (bool): If True, the match is considered a draw.
        k (int): K-factor determining the magnitude of score updates.
    """
    R_winner = elo_scores[winner]
    R_loser = elo_scores[loser]

    # Compute expected win probabilities
    E_winner = 1 / (1 + 10 ** ((R_loser - R_winner) / 400))
    E_loser = 1 - E_winner

    if draw:
        S_winner, S_loser = 0.5, 0.5  # Both players receive a draw score
    else:
        S_winner, S_loser = 1, 0  # Standard win/loss scenario

    # Adjust scores
    elo_scores[winner] += k * (S_winner - E_winner)
    elo_scores[loser] += k * (S_loser - E_loser)



def rank(df: pd.DataFrame, original_column: str, generated_columns: list[str], count: int = 100):
    """
    Performs an ELO ranking system to rank the best generated community note.

    Returns a DataFrame showing:
    - Matchup (which notes were compared)
    - Winner (which note was chosen)
    - Reason (why it was chosen)
    - Updated ELO Scores
    """
    elo_scores = initialize_elo(df, generated_columns)
    elo_win_loss_stats = {col: {"wins": 0, "losses": 0, "draws": 0} for col in generated_columns}
    results = []

    print("Rank start")

    num_rows = len(df)

    for _, row in df.iterrows():
        original_cn = row[original_column]

        # Each row gets count matchups
        matchups_for_this_row = count / num_rows

        # Choose matchups
        while matchups_for_this_row > 0:
            matchups_for_this_row -= 1

            print(f"Matchups for this row left: {matchups_for_this_row}")

            # Choose a and b based on similar ELO scores
            sorted_elo = sorted(elo_scores.items(), key=lambda x: x[1])

            print("Current rankings:")
            # NIce formatting with consistent columns

            print("Column".ljust(30), "ELO".ljust(30), end="\n")  
            for col, elo in reversed(sorted_elo):
                print(f"{col}".ljust(30), end="")
                print(f"{elo}".ljust(30))


            # Pick one randomly and then pick either the one to left or right of it
            if random.random() < 0.5:
                a = random.choice(sorted_elo)
                a_index = sorted_elo.index(a)
                if a_index == 0:
                    b = sorted_elo[a_index + 1]
                elif a_index == len(sorted_elo) - 1:
                    b = sorted_elo[a_index - 1]
                else:
                    b = random.choice([sorted_elo[a_index - 1], sorted_elo[a_index + 1]])
            else:
                # Just pick two random ones
                a = random.choice(sorted_elo)
                while True:
                    b = random.choice(sorted_elo)
                    if a != b:
                        break


            a = a[0]
            b = b[0]


            generated_cn_a = row[a]
            generated_cn_b = row[b]

            # Compare the two generated notes
            while True:
                try:
                    result = compare(original_cn, generated_cn_a, generated_cn_b)
                    break
                except ValueError as e:
                    print("Bad result trying again: ", e)

            if result['choice'].lower() == 'd':
                winner_col = "Draw"
                loser_col = "Draw"
            else:
                winner_col = a if result['choice'].lower() == 'a' else b
                loser_col = b if result['choice'].lower() == 'a' else a

            # Update wins and losses
            if result['choice'].lower() == 'a':
                elo_win_loss_stats[a]["wins"] += 1
                elo_win_loss_stats[b]["losses"] += 1
            elif result['choice'].lower() == 'b':
                elo_win_loss_stats[b]["wins"] += 1
                elo_win_loss_stats[a]["losses"] += 1
            elif result['choice'].lower() == 'd':
                elo_win_loss_stats[a]["draws"] += 1
                elo_win_loss_stats[b]["draws"] += 1

            print(f"{a} elo: {elo_scores[a]} vs {b} elo: {elo_scores[b]}, Winner: {winner_col}")

            # Update ELO scores
            if result['choice'].lower() == 'd':
                update_elo(elo_scores, a, b, draw=True)
            else:
                update_elo(elo_scores, winner_col, loser_col)

            # Store results
            results.append({
                "Id": row["id"],
                "Matchup": f"A: {a} vs B: {b}",
                "Winner": winner_col,
                "Reason": result['reason'],
                "A_New_ELO": elo_scores[a],
                "B_New_ELO": elo_scores[b],
                "Original_CN": original_cn,
                "A's CN": generated_cn_a,
                "B's CN": generated_cn_b
            })

    # Convert to DataFrame
    results_df = pd.DataFrame(results)


    # Ranking will include elo scores and wins/losses
    ranking_results = []
    for col in generated_columns:
        ranking_results.append({
            "Generated_Note": col,
            "ELO": elo_scores[col],
            "Wins": elo_win_loss_stats[col]["wins"],
            "Losses": elo_win_loss_stats[col]["losses"],
            "Draws": elo_win_loss_stats[col]["draws"]
        })
    
    # Display rankings
    ranking_df = pd.DataFrame(ranking_results)
    ranking_df = ranking_df.sort_values(by='ELO', ascending=False)

    return results_df, ranking_df

if __name__ == "__main__":
    # Quick test
    original_cn = "The photo of Mark Zuckerberg was taken in 2012 during a trip to Maui, Hawaii with his wife:  https://www.dailymail.co.uk/news/article-2254889/Mark-Zuckerberg-Priscilla-Chan-surfing-Christmas-Hawaii.html"
    generated_cn = "This image is a fabricated Facebook post attributed to Mark Zuckerberg, making false claims about 'adrenochrome' and Little St. James Island. The real photo of Zuckerberg was taken in Hawaii in 2012. The adrenochrome conspiracy theory is linked to antisemitism and QAnon. [https://www.logicallyfacts.com/fact-checks/no-mark-zuckerberg-did-not-admit-to-ingesting-adrenochrome]"
    print(score(generated_cn, original_cn))

